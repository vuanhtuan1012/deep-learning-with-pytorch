{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Linear Regression supposes that there's a linear relation between inputs and outputs (targets).\n",
    "\n",
    "This notebook shows how to train a linear regression model in PyTorch in two ways:\n",
    "- [from scratch](#1.-Linear-Regression-from-scratch), functions are built manually.\n",
    "- [using PyTorch built-ins function](#2.-Linear-Regression-using-PyTorch-built-ins)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression from scratch\n",
    "\n",
    "The figure below presents the workflow of this part.\n",
    "\n",
    "![lnr-scratch-workflow](images/linear_regression_from_scratch.svg)\n",
    "\n",
    "- [x] Convert inputs & targets to tensors: convert data (*inputs* & *targets*) from numpy arrays to tensors.\n",
    "- [x] Initialize parameters: identify the number of samples, of features and of targets. Initialize *weights* and *bias* to predict target. Theses parameters will be optimized in training process.\n",
    "- [x] Define functions: create *hypothesis function* (model) to predict target from input, and *cost function* (loss function) to compute the difference between the prediction and the target.\n",
    "- [x] Train model: find the *optimal values* of the parameters (weights & bias) by using gradient descent algorithm. Make sure **reset gradients to zero** before the next iteration.\n",
    "- [x] Predict: using optimal parameters to predict target from a given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Prepare data\n",
    "\n",
    "Converting inputs & targets to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "inputs = np.array([[73, 67, 43], \n",
    "              [91, 88, 64], \n",
    "              [87, 134, 58], \n",
    "              [102, 43, 37], \n",
    "              [69, 96, 70]], dtype='float32')\n",
    "\n",
    "# targets\n",
    "targets = np.array([[56, 70], \n",
    "              [81, 101], \n",
    "              [119, 133], \n",
    "              [22, 37], \n",
    "              [103, 119]], dtype='float32')\n",
    "\n",
    "# convert inputs and targets to tensors\n",
    "X = torch.from_numpy(inputs)\n",
    "Y = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 5\n",
      "number of features: 3\n",
      "number of outputs: 2\n"
     ]
    }
   ],
   "source": [
    "# get number of samples (m) and of features (n)\n",
    "m, n = X.shape\n",
    "print('number of samples: %s' % m)\n",
    "print('number of features: %s' % n)\n",
    "\n",
    "# get number of outputs (a)\n",
    "_, a = Y.shape\n",
    "print('number of outputs: %s' % a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "W = torch.randn(a, n, requires_grad=True)  # weights\n",
    "b = torch.randn(a, requires_grad=True)  # bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1. Hypothesis function / Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, W, b):\n",
    "    Y_hat = X @ W.t() + b\n",
    "    return Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2. Cost function / Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fn(Y_hat, Y):\n",
    "    diff = Y_hat - Y\n",
    "    return torch.sum(diff * diff)/diff.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Train model\n",
    "\n",
    "The algorithm Gradient Descent repeats the process of adjusting the weights and biases using the gradients multiple times to reduce the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuanva/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    }
   ],
   "source": [
    "epochs = 100  # define number of iteration\n",
    "lr = 1e-5  # learning rate\n",
    "for i in range(epochs):\n",
    "    Y_hat = model(X, W, b)\n",
    "    cost = cost_fn(Y_hat, Y)\n",
    "    cost.backward()\n",
    "    with torch.no_grad():\n",
    "        W -= W.grad * lr\n",
    "        b -= b.grad * lr\n",
    "        W.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[52.8746, 66.5950]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[75, 63, 44.]])\n",
    "y_hat = model(x, W, b)\n",
    "print(y_hat.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regression using PyTorch built-ins\n",
    "\n",
    "The figure below presents the workflow of this part.\n",
    "\n",
    "![lnr-scratch-workflow](images/linear_regression_pytorch_built_ins.svg)\n",
    "\n",
    "- [x] Convert inputs & targets to tensors: convert data (*inputs* & *targets*) from numpy arrays to tensors. **Make sure** that numpy arrays are in data type `float32`.\n",
    "- [x] Define dataset & dataloader:\n",
    "    - dataset are tuples of inputs & targets.\n",
    "    - dataloader shuffles the dataset and divides a dataset into batches.\n",
    "- [x] Define functions:\n",
    "    - identify the number of features and of targets, set model is a linear function.\n",
    "    - set cost function is a mean squared loss function.\n",
    "- [x] Define optimizer: identifies the algorithm using to adjust model parameters. Set optimzer to use stochastic gradient descent algorithm.\n",
    "- [x] Train model: find the *optimal values* of model parameters by repeating the process of optimizing. **Make sure** reset gradients to zero before the next iteration.\n",
    "- [x] Predict: using optimal parameters to predict target from a given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Prepare data\n",
    "\n",
    "Converting inputs & targets to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "inputs = np.array([[73, 67, 43], \n",
    "              [91, 88, 64], \n",
    "              [87, 134, 58], \n",
    "              [102, 43, 37], \n",
    "              [69, 96, 70], \n",
    "              [74, 66, 43], \n",
    "              [91, 87, 65], \n",
    "              [88, 134, 59], \n",
    "              [101, 44, 37], \n",
    "              [68, 96, 71], \n",
    "              [73, 66, 44], \n",
    "              [92, 87, 64], \n",
    "              [87, 135, 57], \n",
    "              [103, 43, 36], \n",
    "              [68, 97, 70]], dtype='float32')\n",
    "\n",
    "# targets\n",
    "targets = np.array([[56, 70], \n",
    "              [81, 101], \n",
    "              [119, 133], \n",
    "              [22, 37], \n",
    "              [103, 119],\n",
    "              [57, 69], \n",
    "              [80, 102], \n",
    "              [118, 132], \n",
    "              [21, 38], \n",
    "              [104, 118], \n",
    "              [57, 69], \n",
    "              [82, 100], \n",
    "              [118, 134], \n",
    "              [20, 38], \n",
    "              [102, 120]], dtype='float32')\n",
    "\n",
    "# convert to tensors\n",
    "X = torch.from_numpy(inputs)\n",
    "Y = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "dataset = TensorDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data loader\n",
    "batch_size = 5\n",
    "dataloader = DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "tensor([[102.,  43.,  37.],\n",
      "        [ 87., 135.,  57.],\n",
      "        [ 92.,  87.,  64.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 74.,  66.,  43.]])\n",
      "\n",
      "\n",
      "torch.Size([5, 2])\n",
      "tensor([[ 22.,  37.],\n",
      "        [118., 134.],\n",
      "        [ 82., 100.],\n",
      "        [ 81., 101.],\n",
      "        [ 57.,  69.]])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    xs, ys = batch\n",
    "    print(xs.shape)\n",
    "    print(xs.data)\n",
    "    print('\\n')\n",
    "    print(ys.shape)\n",
    "    print(ys.data)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Hypothesis function / Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5470, -0.2511, -0.1040],\n",
      "        [-0.4040, -0.4391, -0.1143]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2857, -0.5363], requires_grad=True)\n",
      "[Parameter containing:\n",
      "tensor([[-0.5470, -0.2511, -0.1040],\n",
      "        [-0.4040, -0.4391, -0.1143]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.2857, -0.5363], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# get number of samples (m) and of features (n)\n",
    "m, n = X.shape\n",
    "\n",
    "# get number of outputs\n",
    "_, a = Y.shape\n",
    "\n",
    "# define hypothesis function\n",
    "model = nn.Linear(n, a)\n",
    "\n",
    "print(model.weight)\n",
    "print(model.bias)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Cost function / Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Define optimizer\n",
    "\n",
    "Optimizer identifies the algorithm using to adjust model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)  # use the algorithm stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, cost_fn, opt, dataloader):\n",
    "    for epoch in range(epochs):\n",
    "        for xs, ys in dataloader:\n",
    "            ys_hat = model(xs)  # predict\n",
    "            cost = cost_fn(ys_hat, ys)  # compute cost\n",
    "            cost.backward()  # compute gradients\n",
    "            opt.step()  # adjust model parameters\n",
    "            opt.zero_grad()  # reset gradients to 0\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('epoch {}/{}, cost: {:.4f}'.format(epoch+1, epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10/100, cost: 353.9998\n",
      "epoch 20/100, cost: 142.3173\n",
      "epoch 30/100, cost: 100.6870\n",
      "epoch 40/100, cost: 111.7669\n",
      "epoch 50/100, cost: 63.0477\n",
      "epoch 60/100, cost: 42.9409\n",
      "epoch 70/100, cost: 28.2862\n",
      "epoch 80/100, cost: 19.6485\n",
      "epoch 90/100, cost: 38.8114\n",
      "epoch 100/100, cost: 16.4094\n"
     ]
    }
   ],
   "source": [
    "fit(100, model, cost_fn, opt, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[54.3244, 68.3188]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[75, 63, 44.]])\n",
    "y_hat = model(x)\n",
    "print(y_hat.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
