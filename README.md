# Deep Learning with PyTorch: Zero to GANs

## Syllabus

1. **PyTorch Basics and Gradient Descent**
	- PyTorch basics: tensors, gradients, and autograd
	- Linear regression & gradient descent from scratch
	- Using PyTorch modules: nn.Linear & nn.functional
2. **Working with Images and Logistic Regression**
	- Training-validation split on the MNIST dataset
	- Logistic regression, softmax & cross-entropy
	- Model training, evaluation & sample predictions
	- **Assignment 2** - Train Your First Model
3. **Training Deep Neural Networks on a GPU**
	- Multilayer neural networks using nn.Module
	- Activation functions, non-linearity & backprop
	- Training models faster using cloud GPUs
	- **Assignment 3** - Feed Forward Neural Networks
4. **Image Classification with Convolutional Neural Networks**
	- Working with 3-channel RGB images
	- Convolutions, kernels & features maps
	- Training curve, underfitting & overfitting
	- **Course Project** - Train a Deep Learning Model from Scratch
5. **Data Augmentation, Regularization, and ResNets**
	- Adding residual layers with batchnorm to CNNs
	- Learning rate annealing, weight decay & more
	- Training a state-of-the-art model in 5 minutes
6. **Image Generation using Generative Adversarial Networks (GANs)**
	- Generative modeling and applications of GANs
	- Training generator and discriminator networks
	- Generating fake digits & anime faces with GANs
	
## Test Math

In line formula $`\sqrt{2}`$

Block formula

```math
SE = \frac{\sigma}{\sqrt{n}}
```

Latex render

<img src="https://latex.codecogs.com/gif.latex?P%28s%20%7C%20O_t%20%29%3D%5Ctext%20%7B%20Probability%20of%20a%20sensor%20reading%20value%20when%20sleep%20onset%20is%20observed%20at%20a%20time%20bin%20%7D%20t%20" />

Github render

<img src="https://render.githubusercontent.com/render/math?math=P%28s%20%7C%20O_t%20%29%3D%5Ctext%20%7B%20Probability%20of%20a%20sensor%20reading%20value%20when%20sleep%20onset%20is%20observed%20at%20a%20time%20bin%20%7D%20t%20">